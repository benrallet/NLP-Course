{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Students:__ benra741, enral465 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Description\n",
    "In this Lab our goal is to implement a search tool based on Google Game apps, where we can write a query as a string with keywords and receive the most similar results.\n",
    "\n",
    "For the implementation we followed 3 steps. The first step is regarding the data extraction and manipulation of HTML codes by using regular expressions for processing the data. For this step we accessed to the webpage where we collected all the App URL’s and processed them in order to collect only the name and the description of every app. The process of the web URL’s is done by cleaning the HTML and storing the description of every app in a separate files, we had to be careful with the encoding of some characters.\n",
    "\n",
    "For the second step, with every app description file we collected, we had to apply preprocessing steps which include the implementation of a function called “preprocess” that removes non-alpha numeric characters, tokenize, lowercase the words, removes stop words and Stem. The preprocessing is needed for the computation of the Term Frequency-Inverse Document Frequency which function (TfidfVectorizer) is already implemented at the “sklearn” package, a matrix with the TF-IDF from the collection of raw documents is created which contains for every row (App) a number from zero to one that calculates which words from the description match with the collection of words we are comparing it.\n",
    "\n",
    "For the last step, a ranked query processor has been created. A string is used as an input, this string needs to be preprocessed and transformed as we did on the preprocessing step. The main objective here is to compute an angle by in order to know which apps are have more relation with our query; in this case we are using the cosine similarity which will return a number from 0 to 1 where 0 means that the query has no relation with an app and 1 is a perfect similarity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Get the webpage content by using functions in \n",
    "__[urllib module](https://docs.python.org/3/library/urllib.html#module-urllib)__.\n",
    "\n",
    "Other libraries are also fine to achieve the crawling.\n",
    "\n",
    "e.g. scrapy, beautifulsoup... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "x = urllib.request.urlopen('https://play.google.com/store/apps/category/GAME?hl=en').read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Get app url by regular expression using functions from __[re module](https://docs.python.org/3/library/re.html?highlight=re#module-re)__.\n",
    "\n",
    "A useful online regular expression check.\n",
    "__[Check your regular expression first](https://regex101.com)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "appreg = r'href=\\\"(/store/apps/details.*?)\\\"'\n",
    "appre = re.compile(appreg)\n",
    "app_url_list = re.findall(appre,x)\n",
    "app_url_list = list(set(app_url_list))\n",
    "print(len(app_url_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Access specific webpage to get description of each app and then store the description in files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "descg = r'itemprop=\\\"description.*?\\\">.*?<div jsname=\\\".*?\\\">(.*?)<\\/div>'\n",
    "desc_reg = re.compile(descg)\n",
    "\n",
    "def cleanHTML(html):\n",
    "    html = re.sub('<.*?>', ' ', html) #remove the tags\n",
    "    html = re.sub('&.*?;', ' ', html) #remove the html symbols (ex: &amp;)\n",
    "    html = re.sub('https?:\\/\\/.*?(\\s|\\'|$)', ' ', html) #remove urls\n",
    "    html = re.sub('[^\\w]', ' ', html) #remove non alpha-numeric or space characters\n",
    "    return html\n",
    "\n",
    "def gettingDescription(html):\n",
    "    desc = re.search(desc_reg,html).group()\n",
    "    return cleanHTML(desc)\n",
    "    \n",
    "files = []\n",
    "names = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < 1000 :\n",
    "    url = app_url_list[0]\n",
    "\n",
    "    app_url_list = app_url_list[1:]\n",
    "\n",
    "    html = urllib.request.urlopen('https://play.google.com' + url +\"&hl=en\").read().decode('utf8')\n",
    "    \n",
    "    # retrieve the name of the app\n",
    "    nameg = r'<title id=\\\"main-title\\\">(.*?) - Android'\n",
    "    name = re.compile(nameg)\n",
    "    if re.search(name, html) != None :\n",
    "        name2 = cleanHTML(re.search(name, html).group())\n",
    "        file_name = 'Files/description_{}.txt'.format(name2)\n",
    "\n",
    "        #check if not already used\n",
    "        if file_name not in files:\n",
    "            desc_url = gettingDescription(html)\n",
    "            temp = re.findall(appre, html)\n",
    "            app_url_list = list(set(app_url_list + temp))  \n",
    "\n",
    "            files.append(file_name)\n",
    "            names.append(name2) # name list update\n",
    "            try:\n",
    "                with open(file_name , 'w') as file:\n",
    "                    print(desc_url, file = file)\n",
    "                    i = i + 1\n",
    "            except:\n",
    "                print(file_name) # files that throw an exception (character issue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Inverted file index (Vector Model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Preprocess text using NLP techniques from __[nltk module](http://www.nltk.org/py-modindex.html)__.\n",
    "\n",
    "Using nltk.download(ID) to get the corpora if it is not downloaded before. __[nltk corpora](http://www.nltk.org/nltk_data/)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.stem\n",
    "\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "# preprocess text\n",
    "def preprocess(s):\n",
    "    tokens = [ word for sent in sent_tokenize(s) for word in word_tokenize(sent) ] # tokenization\n",
    "    tokens = [ token.lower() for token in tokens ] # lowercase\n",
    "    tokens = [ token for token in tokens if token not in stop ] # stopwords )\n",
    "    tokens = [ english_stemmer.stem(token) for token in tokens ] # stem\n",
    "    return(tokens)\n",
    "\n",
    "# loop to go through each file and write back to it\n",
    "for file in files:\n",
    "    with open(file, 'r+') as f:\n",
    "        init = f.read()\n",
    "        f.seek(0)\n",
    "        f.truncate()\n",
    "        text = ' '.join(preprocess(init))\n",
    "        print(text, file=f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...)Compute tdidf using functions from __[scikit-learn module](http://scikit-learn.org/stable/modules/classes.html)__.\n",
    "\n",
    "eg. TfidfVectorizer is used for converting a collection of raw documents to a matrix of TF-IDF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1076, 9667)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "transvector = TfidfVectorizer()\n",
    "corpus = []\n",
    "for file in files: # go through all the documents\n",
    "    with open(file, 'r') as f:\n",
    "        corpus.append(f.readline().strip())\n",
    "\n",
    "tfidf1 = transvector.fit_transform(corpus)\n",
    "tfidf_matrix = tfidf1.toarray()\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Process\n",
    "\n",
    "eg. \"Dragon, Control, hero, running\"\n",
    "\n",
    "eg. \"The hero controls the dragon to run.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['basketbal']\n",
      "[(' Free Throw Basketball   Android', array([ 0.70313571])), (' Dunk Hit Basketball   Android', array([ 0.40440768])), (' Basketball Shots 3D  2013    Android', array([ 0.32648624])), (' Dunkers   Basketball Madness   Android', array([ 0.18303438])), (' Basketball Shots 3D  2010    Android', array([ 0.15318526])), (' Flappy Ball   Ball through the Basket   Android', array([ 0.15107596])), (' Jam League Basketball   Android', array([ 0.11764068])), (' Stickman Football   Android', array([ 0.07774137])), (' Stickman Volleyball   Android', array([ 0.07339062])), (' Pink Gold Diamond Live Theme   Android', array([ 0.03596636]))]\n",
      "['game cook restaur']\n",
      "[(' Hidden Objects Restaurants   Kitchen Games   Android', array([ 0.57740634])), (' My Cafe  Recipes   Stories   World Cooking Game   Android', array([ 0.396865])), (' Bake Cupcakes   Android', array([ 0.34403219])), ('   Food Truck  Match 3 Game Free   Android', array([ 0.33001276])), (' Cooking colorful cupcakes   Android', array([ 0.32378784])), (' Street Food Kitchen Chef   Cooking Game   Android', array([ 0.27971514])), (' Cookbook Master   Master Your Chef Skills    Android', array([ 0.2643161])), (' Cooking pizza for dinner   Android', array([ 0.25248312])), (' SUPER Hot Dog Food Truck    Android', array([ 0.20623804])), (' Cake Shop   Kids Cooking   Android', array([ 0.18460619]))]\n",
      "['race']\n",
      "[(' Drifting Car City Traffic Racing 3d   Android', array([ 0.52807016])), (' Moto Traffic Race 2   Android', array([ 0.49468975])), (' Dino World Bike Race Game   Jurassic Adventure     Android', array([ 0.47867353])), (' Street Racing 3D   Android', array([ 0.46144322])), (' Offroad Car Drifting 3D   Android', array([ 0.42706812])), (' Drag Racing 4x4   Android', array([ 0.41289281])), (' Highway Bike Attack Racer  Moto racing   Android', array([ 0.40427875])), (' Car Racing Simulator 2015   Android', array([ 0.39844433])), (' VRX Space Racer   Free VR Racing Games   Android', array([ 0.38068465])), (' Death Race     Shooting Cars   Android', array([ 0.37779835]))]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import operator\n",
    "\n",
    "def queryProcess(query) :\n",
    "    query = [' '.join(preprocess(query))]\n",
    "    print(query)\n",
    "\n",
    "    query = transvector.transform(query).toarray()\n",
    "    similarity = cosine_similarity(tfidf_matrix, query)\n",
    "\n",
    "    #I added a variable called names so we can return the names of the apps\n",
    "    #print(names)\n",
    "    #In this part we will need to get somehow an order of the most similar results with their names (dictionary of a matrix? how?)\n",
    "    apps_dictionary = {}\n",
    "\n",
    "    for i in range(len(names)) :\n",
    "        apps_dictionary.update({names[i]:similarity[i]})\n",
    "\n",
    "    #sorted(similarity, reverse=True)\n",
    "\n",
    "    sorted_apps_dictionary = sorted(apps_dictionary.items(),key = operator.itemgetter(1),reverse = True)\n",
    "    return sorted_apps_dictionary[0:10]\n",
    "\n",
    "print(queryProcess('basketball'))\n",
    "print(queryProcess('game cooking restaurant'))\n",
    "print(queryProcess('racing'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
